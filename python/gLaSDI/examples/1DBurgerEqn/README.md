The gLaSDI framework is applied to construct a non-intrusive reduced-order model of the **1D Burgers' Equation**.


**Procedure**:
- run `generate_data.py` to generate dataset:
    1. generate initial training parameter cases on a given parameter space
    2. generate a dataset of discrete parameter space for adaptive greedy sampling and evaluation
- run `train_model.py` to train a gLaSDI model by submitting a job using `batch_job.bsub`
    - If the training time exceeds the maximum allowable wall time, the training can be continued by
    updating the following parameters in `train_model.py` and submitting additoinal jobs:
        - `params['retrain'] = True`
        - `save_name` (file name of the trained model)
- run `test_model.py` to evalute the trained model
- run `plot_heatmap.py` to plot the greedy sampling process in terms of the error indicator


For *LC users*, some datasets are available in `/usr/workspace/he10/data/1DBurgerEqn/`, which are used in the numerical examples in the paper. The datasets are generated from the parameter space constituted by the parameters of the initial condition, including the **width** in [0.9,1.1] and the **amplitude** in [0.7,0.9].
- `local4.p`: 2 x 2 parameter cases on the given parameter space, which are initial parameter cases located at the corners of the parameter space
- `local441.p`: 21 x 21 parameter cases on the given parameter space; a dataset of discrete parameter space for adaptive greedy sampling and evaluation


For *non-LC users*, the data can be generated by running `generate_data.py`. For example, to generate n x n discrete parameter cases with the width in [0.9,1.1] and the amplitude in [0.7,0.9], one can set
- `width = np.linspace(0.9,1.1,n)`
- `amp = np.linspace(0.7,0.9,n)`


Note that to enhance the training efficiency, the dataset of a discrete parameter space (e.g., 21 x 21 parameter cases) for adaptive greedy sampling is generated before training starts, which means the solution of the optimal parameter case (with the maximum error indicator) is retrieved from the dataset without calling the solver of the full-order model during training. The proposed gLaSDI framework can be adapted to a continuous parameter space and the solution of sampled parameter cases can be generated by running full-order model simulations during training.