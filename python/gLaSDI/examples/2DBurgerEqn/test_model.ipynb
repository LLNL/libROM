{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from autoencoder import full_network\n",
    "from training import create_feed_dictionary, create_feed_dictionary2, eval_model, max_err_heatmap\n",
    "from sindy_utils import *\n",
    "from error_utils import *\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "from copy import deepcopy\n",
    "import subprocess as sp\n",
    "from error_utils import residual_2Dburger\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def get_cmap(n, name='tab20'):\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "cmap = get_cmap(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_gpu_memory():\n",
    "  _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "\n",
    "  ACCEPTABLE_AVAILABLE_MEMORY = 1024\n",
    "  COMMAND = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "  memory_free_info = _output_to_list(sp.check_output(COMMAND.split()))[1:]\n",
    "  memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "  return memory_free_values\n",
    "\n",
    "device_list = tf.config.list_physical_devices('GPU')\n",
    "free_mem = get_gpu_memory()\n",
    "for i,gpu in enumerate(device_list):\n",
    "    print(f'{gpu}: free memory: {free_mem[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which GPU to use\n",
    "config = tf.ConfigProto(log_device_placement=False, gpu_options=tf.GPUOptions(allow_growth=True,\n",
    "                                                                              visible_device_list='1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Trained gLaSDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + '/fig/nCase121_tstop3_ld3_p1_1e-2_lr1e-3_width100_nDI25_upEP2e4_resNS0.1/'\n",
    "save_name = 'ex9_2022_02_06_08_44_55'\n",
    "params = pickle.load(open(data_path + save_name + '_params.pkl', 'rb'))\n",
    "params['save_name'] = data_path + save_name\n",
    "params['config'] = config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation by One Parameter Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, vel, nt):\n",
    "    # select component\n",
    "    if vel == 1:\n",
    "        data['data'][0]['x'] = data['data'][0].pop('u')\n",
    "        data['data'][0]['dx'] = data['data'][0].pop('du')\n",
    "        data['data'][0].pop('v')\n",
    "        data['data'][0].pop('dv')\n",
    "    elif vel == 2:\n",
    "        data['data'][0]['x'] = data['data'][0].pop('v')\n",
    "        data['data'][0]['dx'] = data['data'][0].pop('dv')\n",
    "        data['data'][0].pop('u')\n",
    "        data['data'][0].pop('du')\n",
    "    elif vel == 3:\n",
    "        data['data'][0]['x'] = np.hstack((data['data'][0]['u'], data['data'][0]['v']))\n",
    "        data['data'][0]['dx'] = np.hstack((data['data'][0]['du'], data['data'][0]['dv']))\n",
    "        \n",
    "    # select time steps\n",
    "    data['data'][0]['x'] = data['data'][0]['x'][:nt+1]\n",
    "    data['data'][0]['dx'] = data['data'][0]['dx'][:nt+1]\n",
    "    data_x = np.copy(data['data'][0]['x'])\n",
    "    data_dx = np.copy(data['data'][0]['dx'])\n",
    "    return data, data_x, data_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Re = params['pde']['Re']\n",
    "nx = params['pde']['nx']\n",
    "ny = nx\n",
    "nt = params['pde']['nt']\n",
    "tstop = params['pde']['tstop']\n",
    "ic = params['pde']['ic']\n",
    "t_test = tstop\n",
    "vel = 3 # 1: u, 2: v, 3: u and v\n",
    "knn = 1\n",
    "amp_arr = np.array([0.7])\n",
    "width_arr = np.array([0.9])\n",
    "test_data = pickle.load(open(f\"/g/g92/he10/Research/data/2DBurgerEqn/local1_Re{Re}_A{amp_arr[0]:.2f}_W{width_arr[0]:.2f}_tstop{tstop:.1f}_nt{nt}_nx{nx}.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nt_test = int(t_test/tstop*nt)\n",
    "t = np.linspace(0,t_test,nt_test+1)\n",
    "test_data, test_data_x, test_data_dx = process_data(test_data, vel, nt_test)\n",
    "\n",
    "u_decoder,du_decoder,u_sim,du_sim,z_encoder,dz_encoder,z_sim,dz_sim,idx,timer_rom = eval_model(test_data['data'][0], params,\n",
    "                                                                                               test_data['param'][0], knn=knn,\n",
    "                                                                                               calc_dz=True, calc_du=True)\n",
    "u_decoder = u_decoder.squeeze()\n",
    "time_rom = timer_rom[1:].sum()\n",
    "print(z_sim.shape, u_sim.shape, u_decoder.shape)\n",
    "print(f'time: {time_rom:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max relative error\n",
    "err_decoder = np.linalg.norm(test_data_x - u_decoder, axis=1) / np.linalg.norm(test_data_x, axis=1)*100\n",
    "err_sindy = np.linalg.norm(test_data_x - u_sim, axis=1) / np.linalg.norm(test_data_x, axis=1)*100\n",
    "print(f'max autoencoder error: {err_decoder.max():.2f} %')\n",
    "print(f'max sindy-decoder error: {err_sindy.max():.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_list = np.linspace(0,nt_test,10).astype(int)\n",
    "fig = plt.figure(figsize=(18,3))\n",
    "for i,step in enumerate(step_list):\n",
    "    ax = fig.add_subplot(1,10,i+1)\n",
    "    ax.imshow(test_data_x[step,:nx*ny].reshape(ny,nx))\n",
    "    ax.set_title(f'u - step: {step}')\n",
    "plt.tight_layout()\n",
    "\n",
    "fig = plt.figure(figsize=(18,3))\n",
    "for i,step in enumerate(step_list):\n",
    "    ax = fig.add_subplot(1,10,i+1)\n",
    "    ax.imshow(u_sim[step,:nx*ny].reshape(ny,nx))\n",
    "    ax.set_title(f'u_pred - step: {step}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_list = np.linspace(0,nt_test,10).astype(int)\n",
    "fig = plt.figure(figsize=(18,3))\n",
    "for i,step in enumerate(step_list):\n",
    "    ax = fig.add_subplot(1,10,i+1)\n",
    "    ax.imshow(test_data_x[step,nx*ny:].reshape(ny,nx))\n",
    "    ax.set_title(f'v - step: {step}')\n",
    "plt.tight_layout()\n",
    "\n",
    "fig = plt.figure(figsize=(18,3))\n",
    "for i,step in enumerate(step_list):\n",
    "    ax = fig.add_subplot(1,10,i+1)\n",
    "    ax.imshow(u_sim[step,nx*ny:].reshape(ny,nx))\n",
    "    ax.set_title(f'v_pred - step: {step}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 24,\n",
    "                     \"font.family\": \"sans-serif\"}) # fontsize for figures\n",
    "\n",
    "fig1 = plt.figure(figsize=(12,5))\n",
    "line_type = ['-','-*','-.','-^','-s']\n",
    "idx = np.arange(0,t.size,10)\n",
    "ax = fig1.add_subplot(121)\n",
    "for i in range(z_encoder.shape[1]):\n",
    "    ax.plot(t, z_encoder[:,i], '-', lw=2, c=cmap(i))\n",
    "    ax.plot(t[idx], z_sim[idx,i], '--o', lw=2, markersize=5, c=cmap(i))\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('z')\n",
    "ax.set_xticks(np.linspace(0,t.max(),5))\n",
    "ax.set_ylim(z_sim.min()*1.1,z_sim.max()*2)\n",
    "ax.tick_params(axis='both', labelsize=24)\n",
    "ax.legend(['Encoder', 'DI'], loc='upper right', frameon=False, fontsize=24)\n",
    "ax.set_xlim(t.min(),t.max())\n",
    "\n",
    "ax = fig1.add_subplot(122)\n",
    "for i in range(z_sim.shape[1]):\n",
    "    ax.plot(t, dz_encoder[:,i], '-', linewidth=2, c=cmap(i))\n",
    "    ax.plot(t[idx], dz_sim[idx,i], '--o', linewidth=2, markersize=5, c=cmap(i))\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('dz/dt')\n",
    "ax.set_xticks(np.linspace(0,t.max(),5))\n",
    "ax.set_xlim(0,t.max())\n",
    "ax.set_ylim(dz_sim.min()*1.1,dz_sim.max()*2.2)\n",
    "ax.tick_params(axis='both', labelsize=24)\n",
    "ax.legend(['Encoder', 'DI'], loc='upper right', frameon=False, fontsize=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(data_path + f\"2Dburger_latent_dynamics.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation by the Prescribed Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn = 3\n",
    "res_name = f'mean'\n",
    "nt_test = int(t_test/tstop*nt)\n",
    "t = np.linspace(0,t_test,nt_test+1)\n",
    "vel = 3 # 1: u, 2: v, 3: u and v\n",
    "\n",
    "amp_test = params['test_param'][:,0]\n",
    "width_test = params['test_param'][:,1]\n",
    "amp_size = amp_test.size\n",
    "width_size = width_test.size\n",
    "num_case = amp_size * width_size\n",
    "max_err = np.zeros([amp_size, width_size])\n",
    "res_norm = np.zeros([amp_size, width_size])\n",
    "sindy_idx = np.zeros([amp_size, width_size])\n",
    "test_data_all = pickle.load(open(f\"/g/g92/he10/Research/data/2DBurgerEqn/local{num_case}_Re{Re}_tstop{tstop:.1f}_nt{nt}_nx{nx}.p\", \"rb\"))\n",
    "\n",
    "speed_up = 0\n",
    "count = 0\n",
    "timer_rom = np.zeros(4)\n",
    "start_time = time()\n",
    "for i,a in enumerate(amp_test):\n",
    "    for j,w in enumerate(width_test):\n",
    "        print(f\"{count+1}/{num_case}: {test_data_all['param'][count]}\")\n",
    "        test_data = {}\n",
    "        test_data['data'] = [deepcopy(test_data_all['data'][count])]\n",
    "        test_data['param'] = [deepcopy(test_data_all['param'][count])]\n",
    "        test_data, test_data_x,_ = process_data(test_data, vel, nt_test)\n",
    "        _,_,u_sim,_,_,_,_,_,idx,t_rom = eval_model(test_data['data'][0], params, \n",
    "                                                   test_data['param'][0], knn=knn)\n",
    "        timer_rom += t_rom\n",
    "        sindy_idx[i,j] = idx+1\n",
    "        \n",
    "        # max error of all time steps\n",
    "        max_err[i,j] = (np.linalg.norm(test_data_x - u_sim, axis=1) \\\n",
    "                                        / np.linalg.norm(test_data_x, axis=1)*100).max()\n",
    "        \n",
    "        # residual norm\n",
    "        res_norm[i,j] = err_indicator(u_sim, params, err_type=params['err_type'])\n",
    "        count += 1\n",
    "end_time = time()\n",
    "time_rom = timer_rom[1:].sum()/num_case # from Step 2 to 4\n",
    "time_sim = 38.4 # seconds\n",
    "speed_up = time_sim / time_rom\n",
    "print(f'Time taken: {end_time-start_time:.2f} s, {(end_time-start_time)/60:.2f} mins')\n",
    "print(f'Average speed up: {speed_up:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_grid, w_grid = np.meshgrid(amp_test, width_test)\n",
    "param_list = np.hstack([a_grid.flatten().reshape(-1,1), w_grid.flatten().reshape(-1,1)])\n",
    "a_grid, w_grid = np.meshgrid(np.arange(amp_test.size), np.arange(width_test.size))\n",
    "idx_list = np.hstack([a_grid.flatten().reshape(-1,1), w_grid.flatten().reshape(-1,1)])\n",
    "\n",
    "idx_param = []\n",
    "for i,ip in enumerate(params['param']):\n",
    "    idx = np.argmin(np.linalg.norm(param_list-ip, axis=1))\n",
    "    idx_param.append((idx, np.array([param_list[idx,0], param_list[idx,1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_err_train = []\n",
    "res_norm_train = []\n",
    "for i in idx_param:\n",
    "    idd = i[0]\n",
    "    max_err_train.append(max_err[idx_list[idd,0],idx_list[idd,1]])\n",
    "    res_norm_train.append(res_norm[idx_list[idd,0],idx_list[idd,1]])\n",
    "max_err_train = np.stack(max_err_train)\n",
    "res_norm_train = np.stack(res_norm_train)\n",
    "err_ratio_train = res_norm_train / max_err_train\n",
    "err_ratio_train_mean = err_ratio_train.mean()\n",
    "res_norm_tol = err_ratio_train_mean * params['tol2']\n",
    "print(f'tolerance of residual norm (mean): {res_norm_tol:.5f}')\n",
    "print(f\"tolerance of residual norm (reg_max): {params['tol']:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,4))\n",
    "ax = fig.add_subplot(131)\n",
    "ax.plot(np.arange(1,res_norm.size+1), res_norm.flatten(), 'r.', label='res_norm_'+res_name)\n",
    "ax.set_ylabel('Errors', fontsize=14)\n",
    "ax.tick_params(labelsize=14)\n",
    "ax.grid()\n",
    "ax.legend(fontsize=14)\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "ax.plot(np.arange(1,res_norm.size+1), max_err.flatten(), 'b.', label='maxRelErr')\n",
    "ax.set_ylabel('Errors', fontsize=14)\n",
    "ax.tick_params(labelsize=14)\n",
    "ax.grid()\n",
    "ax.legend(fontsize=14)\n",
    "\n",
    "ax = fig.add_subplot(133)\n",
    "x = max_err.flatten().reshape(-1,1)\n",
    "y = res_norm.flatten().reshape(-1,1)\n",
    "reg = LinearRegression().fit(x, y)\n",
    "y_pred = reg.predict(x)\n",
    "y_diff = y - y_pred\n",
    "x_test = np.linspace(0,max_err.max(),2).reshape(-1,1)\n",
    "y_test = reg.predict(x_test)\n",
    "y_test1 = reg.coef_ * x_test + reg.intercept_+ y_diff.min()\n",
    "y_test2 = reg.coef_ * x_test + reg.intercept_+ y_diff.max()\n",
    "y_test3 = reg.coef_ * params['tol2'] + reg.intercept_+ y_diff.max()\n",
    "ax.plot(max_err.flatten(), res_norm.flatten(), 'g.')\n",
    "ax.plot(x_test,y_test,'r-')\n",
    "ax.plot(x_test,y_test1,'r--')\n",
    "ax.plot(x_test,y_test2,'r--')\n",
    "\n",
    "x_test2 = np.linspace(0,params['tol2'],2).reshape(-1,1)\n",
    "y_test2 = err_ratio_train_mean * x_test2\n",
    "ax.plot([x_test2.max(),x_test2.max()],[0,max(y_test3,res_norm_tol)],'k--')\n",
    "ax.plot(x_test2.max(),res_norm_tol,'b.',markersize=15, label='mean')\n",
    "ax.plot(params['tol2'],y_test3,'r.',markersize=15, label='reg')\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "ax.set_xlabel('$Max relative error (%)$', fontsize=16)\n",
    "ax.set_ylabel('Residual norm', fontsize=16)\n",
    "ax.tick_params(labelsize=16)\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(data_path + f'residual_norm_{res_name}_knn{knn}.png')\n",
    "print(max_err.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of DIs: {len(idx_param)}')\n",
    "max_err_heatmap(max_err, sindy_idx, params, amp_test, width_test, data_path, idx_list, idx_param,\n",
    "                xlabel='Width', ylabel='Amplitude', dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the residual-based errors are scaled by the \"scale\" parameter\n",
    "max_err_heatmap(res_norm, sindy_idx, params, amp_test, width_test, data_path, idx_list, idx_param,\n",
    "                xlabel='Width', ylabel='Amplitude', label='Residual Norm', dtype='float', scale=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfvenv",
   "language": "python",
   "name": "tfvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
